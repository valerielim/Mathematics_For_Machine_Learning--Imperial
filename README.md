# Mathematics_For_Machine_Learning--Imperial

### Week 1 

* [Introduction](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week1/W1%20%E2%80%93%20Intro.md)
* [Practice Assignment: Exploring parameter space](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week1/W1%20%E2%80%93%20Assignment%20%E2%80%93%20Exploring%20Parameter%20Space%20.md)
* [Practice Assignment: Solving simultaneous equations](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week1/W1%20%E2%80%93%20Assignment%20%E2%80%93%20Simultaneous%20Equations.md) 
* [Practice Assignment: Doing vector operations](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week1/W1%20%E2%80%93%20Assignment%20%E2%80%93%20Doing%20vector%20operations.md)

Concepts

* vector addition `[a, b] + [c, d] = [a+c, b+d]`
* vector subtraction `[a, b] - [c, d] = [a-c, b-d]`
* identifying the right vector in a 2d space [x, y]

### Week 2 

* [Lecture](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week2/W2%20%E2%80%93%20Lecture.md) 
* [Practice Assignment: Dot product of vectors](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week2/W2%20%E2%80%93%20Assignment%20%E2%80%93%20Dot%20Product%20of%20Vectors.md)
* [Practice Assignment: Changing Basis](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week2/W2%20%E2%80%93%20Assignment%20%E2%80%93%20Changing%20Basis.md)
* [Practice Assignment: Linear Dependency](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week2/W2%20%E2%80%93%20Assigment%20%E2%80%93%20Linear%20Dependency%20of%20a%20set%20of%20vectors%20.md) 
* [Assignment: Vector Operations Assessment](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week2/W2%20%E2%80%93%20Graded%20Assignment%20%E2%80%93%20Vector%20Operations%20Assessment.md) 

Concepts

* Calculate dot product of one vector with another (e.g., `r.s`) 
* Calculate length of vector through modulus, or dot product with itself (e.g., length of `r = r.r` 
* Applying cosine rule to test for orthogonality, $r.s = |r||s|\cos\theta$, and if $r.s = 0$ then they are indeed at 90" to each other 
* Calculate the scalar projection of one vector onto another, and give the answer as a number (ratio, fraction, percentage) representing the partial length of the second vector: ${r.s\}over{|r|}$
* Calculate the vector projection of one vector onto another, and give the answer as a new vector $r{r.s}\over{r.r}$
* Change the basis vectors to represent an existing vector as a function of new unit vectors

### Week 3

* [Lecture](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week3/W3%20%E2%80%93%20Lecture.md) 
* [Practice Assignment: Solving linear equations using the inverse matrix](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week3/W3%20%E2%80%93%20Assignment%20%E2%80%93%20Solving%20linear%20equations%20using%20inverse%20matrix%20.md) 
* [Practice Assignment: Using matrices to make transformations](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week3/W3%20%E2%80%93%20Assignment%20%E2%80%93%20Using%20matrices%20to%20make%20transformations.md) 
* [Graded Assignment: Identifying Special Matrices (Jupyter)](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week3/W3%20%E2%80%93%20Graded%20Assignment%20%E2%80%93%20IdentifyingSpecialMatrices.ipynb) 

Concepts

* Matrix **clockwise** rotation by angle $\theta\$ using the formula: 

$$\begin{bmatrix} \cos\theta & \sin\theta \\\ 
-\sin\theta/ & \cos\theta\end{bmatrix}
\begin{bmatrix} x \\\ y\end{bmatrix}$$

* Solving simultaneous equations by elimination, substitution. Find the inverse of a matrix through performing these operations on the identity matrix. 
* Recap: Area of parallelogram is `ad-bc` 
* Understand that we should check ALL basis vectors are **linearly independent** else we will not be able to calculate its inverse or its determinant 

### Week 4 
 
* [Lecture](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week4/W4%20%E2%80%93%20Lecture.md) 
* [Practice Assignment: Non-square matrix multiplication](https://github.com/valerielim/Mathematics_For_Machine_Learning--Imperial/blob/main/week4/W4%20%E2%80%93%20Assignment%20%E2%80%93%20Non-square%20Matrix%20Multiplication.md) 
* [Practice Assignment: VERY HARD SHIT DONT LOOK] 